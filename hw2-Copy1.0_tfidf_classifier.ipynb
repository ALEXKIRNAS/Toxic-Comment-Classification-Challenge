{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - TF-IDF Classifier\n",
    "\n",
    "Ваша цель обучить классификатор который будет находить \"токсичные\" комментарии и опубликовать решения на Kaggle [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "В процессе обучения нужно ответить на ***[вопросы](https://docs.google.com/forms/d/e/1FAIpQLSd9mQx8EFpSH6FhCy1M_FmISzy3lhgyyqV3TN0pmtop7slmTA/viewform?usp=sf_link)***\n",
    "\n",
    "Данные можно скачать тут - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('./input/train.csv').fillna('Unknown')\n",
    "test = pd.read_csv('./input/test.csv').fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стадартными подходами для анализа текста являются [Bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) и его модификация [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
    "\n",
    "Они реалзованны в `sklearn` в виде [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) и [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "Более подробней про них можно посмотреть [тут](https://github.com/udsclub/workshop/blob/master/notebooks/UDS-workshop-feature-extraction-and-engineering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azarichkovyi/Projects/Mask_RCNN/env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "re_tok = re.compile('([%s“”¨«»®´·º½¾¿¡§£₤‘’])' % string.punctuation)\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(' u ', 'you', text)\n",
    "    text = re.sub('\\nu ', 'you', text)\n",
    "    text = re.sub(' u\\n', 'you', text)\n",
    "    text = re.sub(\"fucksex\", 'fuck sex', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def cleanupDoc(s):\n",
    "    s = clean_text(s)\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    stopset.add('wikipedia')\n",
    "    tokens =sequence=text_to_word_sequence(s, \n",
    "                                           filters=\"\\\"!'#$%&()*+,-˚˙./:;‘“<=·>?@[]^_`{|}~\\t\\n\",\n",
    "                                           lower=True,\n",
    "                                           split=\" \")\n",
    "    cleanup = \" \".join(filter(lambda word: word not in stopset, tokens))\n",
    "    return cleanup\n",
    "\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', cleanupDoc(s)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуйте разные Vectorizer и разные размеры n-gramm, стоп-слова, обрезку редких слов, обрезку слишком частых слов\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                  ngram_range=(1, 2),\n",
    "                                  tokenizer=tokenize,\n",
    "                                  stop_words='english',\n",
    "                                  max_df=0.9,\n",
    "                                  min_df=3,\n",
    "                                  strip_accents='unicode', \n",
    "                                  use_idf=True,\n",
    "                                  smooth_idf=True, \n",
    "                                  sublinear_tf=True,\n",
    "                                  max_features=300000)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                                  smooth_idf=True,\n",
    "                                  tokenizer=tokenize,\n",
    "                                  strip_accents='unicode',\n",
    "                                  analyzer='char',\n",
    "                                  max_df=0.9,\n",
    "                                  min_df=3,\n",
    "                                  ngram_range=(1, 4),\n",
    "                                  max_features=300000)\n",
    "\n",
    "#vectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=2)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_features = sparse.hstack([train_char_features, train_word_features])\n",
    "test_word_features = sparse.hstack([test_char_features, test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump([train_word_features, test_word_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    train_word_features, test_word_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опубликуйте лучшие решение на [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, \n",
    "                 C=3.15, \n",
    "                 dual=False, \n",
    "                 solver='newton-cg', \n",
    "                 max_iter=1000,\n",
    "                 tol=0.00001,\n",
    "                 n_jobs=1):\n",
    "        \n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "        self.max_iter = max_iter\n",
    "        self.solver = solver\n",
    "        self.tol = tol\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        y = y\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, \n",
    "                                       dual=self.dual,\n",
    "                                       class_weight='balanced',\n",
    "                                       solver=self.solver, \n",
    "                                       max_iter=self.max_iter,\n",
    "                                       tol=self.tol,\n",
    "                                       n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "train_submission = pd.DataFrame.from_dict({'id': train['id']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0xCAFFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severe_toxic\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done   2 out of  30 | elapsed:  2.1min remaining: 29.0min\n",
      "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC best: 0.9893\n",
      "NbSvmClassifier(C=0.25, dual=False, max_iter=100, n_jobs=1,\n",
      "        solver='liblinear', tol=0.001)\n",
      "obscene\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done   2 out of  30 | elapsed:  2.0min remaining: 28.7min\n",
      "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC best: 0.9938\n",
      "NbSvmClassifier(C=0.27, dual=False, max_iter=100, n_jobs=1,\n",
      "        solver='liblinear', tol=0.001)\n",
      "threat\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done   2 out of  30 | elapsed:  1.9min remaining: 27.3min\n",
      "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC best: 0.9889\n",
      "NbSvmClassifier(C=0.25, dual=False, max_iter=100, n_jobs=1,\n",
      "        solver='liblinear', tol=0.001)\n",
      "insult\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done   2 out of  30 | elapsed:  2.3min remaining: 31.8min\n",
      "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC best: 0.9859\n",
      "NbSvmClassifier(C=0.25, dual=False, max_iter=100, n_jobs=1,\n",
      "        solver='liblinear', tol=0.001)\n",
      "identity_hate\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done   2 out of  30 | elapsed:  2.6min remaining: 35.9min\n",
      "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC best: 0.9839\n",
      "NbSvmClassifier(C=0.25, dual=False, max_iter=100, n_jobs=1,\n",
      "        solver='liblinear', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "n_jobs = 30\n",
    "\n",
    "for class_name in class_names[1:]:\n",
    "    print(class_name)\n",
    "    params = {\n",
    "        'C': [0.25, 0.27, 0.30, 0.32, 0.35, 0.36]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        estimator=NbSvmClassifier(), \n",
    "        param_grid=params,\n",
    "        cv=kf,\n",
    "        error_score=1,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # perform grid search on TRAIN dataset ('is_train' filtering)\n",
    "    gs.fit(\n",
    "        X=train_word_features,\n",
    "        y=np.array(train[class_name]),\n",
    "    )\n",
    "    \n",
    "    best_score = gs.best_score_\n",
    "    best_estimator = gs.best_estimator_\n",
    "    print('ROC-AUC best: {:.4f}'.format(best_score))\n",
    "    print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_indices, val_indices, class_name, params):\n",
    "    classifier = NbSvmClassifier(**params)\n",
    "    \n",
    "    csr = train_word_features.tocsr()\n",
    "    X_train = csr[train_indices]\n",
    "    y_train = np.array(train[class_name])[train_indices]\n",
    "    \n",
    "    X_test = csr[val_indices]\n",
    "    y_test = np.array(train[class_name])[val_indices]\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    train_proba = classifier.predict_proba(X_train)[:, 1]\n",
    "    val_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "    sub_proba = classifier.predict_proba(test_word_features)[:, 1]\n",
    "    \n",
    "    train_score = roc_auc_score(y_train, train_proba)\n",
    "    val_score = roc_auc_score(y_test, val_proba)\n",
    "    \n",
    "    return train_score, val_score, val_proba, sub_proba, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: toxic\n",
      "\tTrain ROC-AUC: 0.9978304078882712\n",
      "\tVal ROC-AUC: 0.9822736926333253\n",
      "Class: severe_toxic\n",
      "\tTrain ROC-AUC: 0.9989935654950308\n",
      "\tVal ROC-AUC: 0.9892890605805237\n",
      "Class: obscene\n",
      "\tTrain ROC-AUC: 0.998196392622342\n",
      "\tVal ROC-AUC: 0.9938348132163235\n",
      "Class: threat\n",
      "\tTrain ROC-AUC: 0.9999255227616166\n",
      "\tVal ROC-AUC: 0.9886813292459614\n",
      "Class: insult\n",
      "\tTrain ROC-AUC: 0.9961497833194933\n",
      "\tVal ROC-AUC: 0.9858546460432521\n",
      "Class: identity_hate\n",
      "\tTrain ROC-AUC: 0.9995963786512669\n",
      "\tVal ROC-AUC: 0.9838891079223352\n",
      "Total: 0.9873037749402869\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "cv_params = [\n",
    "    {'C': 0.7},\n",
    "    {'C': 0.25},\n",
    "    {'C': 0.27},\n",
    "    {'C': 0.25},\n",
    "    {'C': 0.25},\n",
    "    {'C': 0.25},\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print('Class: %s' % class_name)\n",
    "    \n",
    "    sub_probas = np.zeros(shape=(len(test), ))\n",
    "    train_probas = np.zeros(shape=(len(train), ))\n",
    "    \n",
    "    kf = KFold(n_splits=predictors, shuffle=True, random_state=0xCAFFE)\n",
    "    \n",
    "    train_scores, val_scores = [], []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=predictors) as executor:\n",
    "        \n",
    "        futures = (executor.submit(training, \n",
    "                                   train_indices, \n",
    "                                   val_indices,\n",
    "                                   class_name,\n",
    "                                   cv_params[i]) \n",
    "                   for train_indices, val_indices in kf.split(train))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            train_score, val_score, val_proba, sub_proba, val_indices = future.result()\n",
    "            train_scores.append(train_score)\n",
    "            val_scores.append(val_score)\n",
    "            \n",
    "            train_probas[val_indices] += val_proba\n",
    "            sub_probas += sub_proba / predictors\n",
    "    \n",
    "    scores.append(np.mean(val_scores))\n",
    "    print('\\tTrain ROC-AUC: %s' % np.mean(train_scores))\n",
    "    print('\\tVal ROC-AUC: %s' % np.mean(val_scores))\n",
    "    \n",
    "    submission[class_name] = sub_probas\n",
    "    train_submission[class_name] = train_probas\n",
    "    \n",
    "print('Total: %s' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035808</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.601958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.032918</td>\n",
       "      <td>0.005747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.038505</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.025838</td>\n",
       "      <td>0.004672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.003191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.003576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  1.000000      0.717001  1.000000  0.035808  0.999616   \n",
       "1  0000247867823ef7  0.020538      0.006018  0.017585  0.001476  0.032918   \n",
       "2  00013b17ad220c46  0.038505      0.005027  0.022191  0.001384  0.025838   \n",
       "3  00017563c3f7919a  0.006525      0.003359  0.010744  0.003425  0.013015   \n",
       "4  00017695ad8997eb  0.057824      0.003986  0.018766  0.001482  0.029788   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.601958  \n",
       "1       0.005747  \n",
       "2       0.004672  \n",
       "3       0.003191  \n",
       "4       0.003576  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_nb_logistic_regression_100.csv', index=False)\n",
    "train_submission.to_csv('train_nb_logistic_regression_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
