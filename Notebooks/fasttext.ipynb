{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText.FastText import train_supervised, fasttext, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('data/train_preprocessed.csv').fillna(' ')\n",
    "test = pd.read_csv('data/test_preprocessed.csv').fillna(' ')\n",
    "\n",
    "tr_ids = train[['id']]\n",
    "train[class_names] = train[class_names].astype(np.int8)\n",
    "target = train[class_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(rez):\n",
    "    probs = []\n",
    "    for r, prob in zip(rez[0], rez[1]):\n",
    "        if r[0][-1] == '1':\n",
    "            probs.append(prob[0])\n",
    "        else:\n",
    "            probs.append(1 - prob[0])\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_data, train_indices, val_indices, target, test_data):\n",
    "    \n",
    "    df_train = train_data.loc[train_indices]\n",
    "    df_val = train_data.loc[val_indices]\n",
    "    \n",
    "    df_train[target + '_ft'] = df_train[target].apply(lambda x: '__label__1 ' if x == 1 else '__label__0 ')\n",
    "    df_train[[target + '_ft', 'comment_text']].to_csv('train_fastText.csv', index=False, header=False)\n",
    "    \n",
    "    d = subprocess.Popen(\"/home/ladmin/fastText-0.1.0/fasttext supervised -input /home/ladmin/toxic_comments/train_fastText.csv -output /home/ladmin/toxic_comments/fasttext_model -pretrainedVectors /home/ladmin/toxic_comments/embeddings/crawl-300d-2M.vec -loss hs -minCount 5 -dim 300\".split())\n",
    "    d.communicate()\n",
    "    classifier = load_model('fasttext_model.bin')\n",
    "\n",
    "    \n",
    "    val_proba = np.array(get_probs(classifier.predict(list(df_val['comment_text']))))\n",
    "    sub_proba = np.array(get_probs(classifier.predict(list(test_data['comment_text']))))\n",
    "    \n",
    "#     train_score = roc_auc_score(df_train[target], train_proba)\n",
    "    val_score = roc_auc_score(df_val[target], val_proba)\n",
    "    \n",
    "    return val_score, val_proba, sub_proba, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "train_submission = pd.DataFrame.from_dict({'id': train['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: toxic\n",
      "\tVal ROC-AUC: 0.9735575055198786\n",
      "Class: severe_toxic\n",
      "\tVal ROC-AUC: 0.9823391797615162\n",
      "Class: obscene\n",
      "\tVal ROC-AUC: 0.9807298632133372\n",
      "Class: threat\n",
      "\tVal ROC-AUC: 0.9839737348846651\n",
      "Class: insult\n",
      "\tVal ROC-AUC: 0.973695169772277\n",
      "Class: identity_hate\n",
      "\tVal ROC-AUC: 0.9733915322919167\n",
      "Total: 0.9781052488012031\n"
     ]
    }
   ],
   "source": [
    "predictors = 5\n",
    "scores = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print('Class: %s' % class_name)\n",
    "    \n",
    "    sub_probas = np.zeros(shape=(len(test), ))\n",
    "    train_probas = np.zeros(shape=(len(train), ))\n",
    "    \n",
    "    kf = KFold(n_splits=predictors, shuffle=True, random_state=42)\n",
    "    \n",
    "    train_scores, val_scores = [], []\n",
    "    for train_indices, val_indices in kf.split(train):\n",
    "        val_score, val_proba, sub_proba, val_indices = training(train, train_indices, val_indices, class_name, test)\n",
    "\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        train_probas[val_indices] += val_proba\n",
    "        sub_probas += sub_proba / predictors\n",
    "    \n",
    "        scores.append(np.mean(val_scores))\n",
    "    print('\\tVal ROC-AUC: %s' % np.mean(val_scores))\n",
    "    \n",
    "    submission[class_name] = sub_probas\n",
    "    train_submission[class_name] = train_probas\n",
    "    \n",
    "print('Total: %s' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>0.998148</td>\n",
       "      <td>0.052779</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.152029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.012161</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999887      0.157253  0.998148  0.052779  0.880165   \n",
       "1  0000247867823ef7  0.000070      0.000168  0.000101 -0.000006  0.000558   \n",
       "2  00013b17ad220c46  0.000002     -0.000007 -0.000006 -0.000010  0.000007   \n",
       "3  00017563c3f7919a  0.000682      0.000420  0.002082  0.000128  0.002113   \n",
       "4  00017695ad8997eb  0.012161      0.000313  0.000245  0.000067  0.000747   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.152029  \n",
       "1       0.000376  \n",
       "2      -0.000008  \n",
       "3       0.000134  \n",
       "4       0.000012  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/submission_fasttext.csv', index=False)\n",
    "train_submission.to_csv('data/train_fasttext.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
