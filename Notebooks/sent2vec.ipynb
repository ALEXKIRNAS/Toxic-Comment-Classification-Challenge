{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sent2vec\n",
    "model = sent2vec.Sent2vecModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model('embeddings/twitter_unigrams.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('data/test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = pd.read_csv('data/train_preprocessed.csv').fillna(' ')\n",
    "test_prep = pd.read_csv('data/test_preprocessed.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train_prep['comment_text']\n",
    "test['comment_text'] = test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sent2vec_emb'] = train['comment_text'].map(lambda text: model.embed_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sent2vec_emb'] = test['comment_text'].map(lambda text: model.embed_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/test_s2v_emb.csv', index=False)\n",
    "train.to_csv('data/train_s2v_emb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram_send\n",
    "telegram_send.send(['Sen2Vec saved'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgm_params = {'learning_rate': 0.2,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "#               'verbosity': 1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 12,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "\n",
    "rounds_lookup = {'toxic': 140,\n",
    "             'severe_toxic': 50,\n",
    "             'obscene': 80,\n",
    "             'threat': 80,\n",
    "             'insult': 70,\n",
    "             'identity_hate': 80}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(train['sent2vec_emb'].values, axis=0), train['threat'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = lgb.LGBMClassifier(**lgm_params, n_estimators=rounds_lookup['threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(application='binary', bagging_fraction=0.8,\n",
       "        boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        data_random_seed=2, feature_fraction=0.6, lambda_l1=1, lambda_l2=1,\n",
       "        learning_rate=0.2, max_depth=-1, metric='auc',\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=80, n_jobs=-1, nthread=12, num_leaves=31,\n",
       "        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834147318601812"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_indices, val_indices, class_name, params):   \n",
    "    csr = np.stack(train['sent2vec_emb'].values, axis=0)\n",
    "    X_train = csr[train_indices]\n",
    "    y_train = np.array(train[class_name])[train_indices]\n",
    "    \n",
    "    X_test = csr[val_indices]\n",
    "    y_test = np.array(train[class_name])[val_indices]\n",
    "    \n",
    "    classifier = lgb.LGBMClassifier(**lgm_params, n_estimators=params)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    train_proba = classifier.predict_proba(X_train)[:, 1]\n",
    "    val_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "    sub_proba = classifier.predict_proba(np.stack(test['sent2vec_emb'].values, axis=0))[:, 1]\n",
    "    \n",
    "    train_score = roc_auc_score(y_train, train_proba)\n",
    "    val_score = roc_auc_score(y_test, val_proba)\n",
    "    \n",
    "    return train_score, val_score, val_proba, sub_proba, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "train_submission = pd.DataFrame.from_dict({'id': train['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: toxic\n",
      "\tVal ROC-AUC: 0.9637572004981279\n",
      "Class: severe_toxic\n",
      "\tVal ROC-AUC: 0.9813609426898129\n",
      "Class: obscene\n",
      "\tVal ROC-AUC: 0.9734490591721849\n",
      "Class: threat\n",
      "\tVal ROC-AUC: 0.5952066730214401\n",
      "Class: insult\n",
      "\tVal ROC-AUC: 0.9703889429008807\n",
      "Class: identity_hate\n",
      "\tVal ROC-AUC: 0.9744114660420191\n",
      "Total: 0.9297635813510875\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictors = 5\n",
    "scores = []\n",
    "for i, class_name in enumerate([class_names]):\n",
    "    print('Class: %s' % class_name)\n",
    "    \n",
    "    sub_probas = np.zeros(shape=(len(test), ))\n",
    "    train_probas = np.zeros(shape=(len(train), ))\n",
    "    \n",
    "    kf = KFold(n_splits=predictors, shuffle=True, random_state=42)\n",
    "    \n",
    "    train_scores, val_scores = [], []\n",
    "    for train_indices, val_indices in kf.split(train):\n",
    "        train_score, val_score, val_proba, sub_proba, val_indices = training(train_indices, val_indices, class_name, rounds_lookup[class_name])\n",
    "\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        train_probas[val_indices] += val_proba\n",
    "        sub_probas += sub_proba / predictors\n",
    "    \n",
    "        scores.append(np.mean(val_scores))\n",
    "    print('\\tVal ROC-AUC: %s' % np.mean(val_scores))\n",
    "    \n",
    "    submission[class_name] = sub_probas\n",
    "    train_submission[class_name] = train_probas\n",
    "    \n",
    "print('Total: %s' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.362346</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.414119</td>\n",
       "      <td>0.977943</td>\n",
       "      <td>0.895989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.400042</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.076606</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.033204</td>\n",
       "      <td>0.400328</td>\n",
       "      <td>0.036823</td>\n",
       "      <td>0.008138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.400005</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.029466</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.400063</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999455      0.362346  0.984940  0.414119  0.977943   \n",
       "1  0000247867823ef7  0.012253      0.000960  0.010627  0.400042  0.009683   \n",
       "2  00013b17ad220c46  0.076606      0.005751  0.033204  0.400328  0.036823   \n",
       "3  00017563c3f7919a  0.001581      0.000333  0.002956  0.400005  0.002386   \n",
       "4  00017695ad8997eb  0.029466      0.001444  0.013087  0.400063  0.035649   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.895989  \n",
       "1       0.001080  \n",
       "2       0.008138  \n",
       "3       0.000041  \n",
       "4       0.000388  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/submission_sen2vec.csv', index=False)\n",
    "train_submission.to_csv('data/train__sen2vec.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
